Efficient Pure Ruby Unicode Normalization (eprun)
=================================================

(pronounced e-prune)

The Talk
--------

Please see the
[Internationalization & Unicode Conference 37](http://www.unicodeconference.org/)
talk on
[Implementing Normalization in Pure Ruby - the Fast and Easy Way](http://www.sw.it.aoyama.ac.jp/2013/pub/RubyNorm/).

Directories and Files
---------------------

*   lib/normalize.rb: The core normalization code.
*   lib/string_normalize.rm: String#normalize.
*   lib/generate.rb: Generation script, generates lib/normalize_tables.rb
    from data/UnicodeData.txt and data/CompositionExclusions.txt.
    This needs to be run only once when updating to a new Unicode version.
*   lib/normalize_tables.rb: Data used for normalization,
    automatically generated by lib/generate.rb.
*   data/: All three files in this directory are downloaded from the
    [Unicode Character Database](http://www.unicode.org/Public/UCD/latest/ucd/).
    They are currently at Unicode version 6.3. They need to be updated for
    a newer Unicode version (happens about once a year).
*   test/test_normalize.rb: Tests for lib/string_normalize.rb,
    using data/NormalizationTest.txt.
*   benchmark/benchmark.rb: Runs the benchmark with example text files.
    Automatically checks for existing gems/libraries; if e.g. the unicode_util
    gem is not available, that part of the benchmark is skipped.
    This also applies to eprun, which will not be run on Ruby 1.8.
*   benchmark/Deutsch_.txt, Japanese_.txt, Korean_.txt, Vietnamese_.txt:
    example texts extracted from random Wikipedia pages
    (see http://en.wikipedia.org/wiki/Wikipedia:Random).
    The languages are choosen based on number of characters affected
    by normalization (Deutsch < Japanese < Vietnamese < Korean).
    These files have somewhat differing lengths,
    so the results cannot directly be compared across languages.
    Adding other files with ending "_.txt" will include them in
    the benchmark.
*   benchmark/benchmark_results.rb:
    Results of benchmark for eprun, unicode_utils, and twitter_cldr.
    Eprun and unicode_utils normalizations are run 100 times each,
    twitter_cldr is run only 1 time (didn't want to wait any longer).

TODOs and Ideas
---------------
*   Publish as a gem, or several gems.
*   Deal better with encodings other than UTF-8.
*   Add methods such as String#nfc, String#nfd,...
*   Add methods for normalization variants.
*   See talk for more.
